{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430955c1",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3280827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import face_recognition as fr\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae94d2",
   "metadata": {},
   "source": [
    "#### Importing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc92a4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aamir Khan.jpg', 'Salman Khan.jpg', 'Shah Rukh Khan.jpg', 'Shreyansh.jpg']\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Dell\\ML projects\\Image processing\\FaceRecognitionProject\\ImagesAttendance\"\n",
    "\n",
    "#list to hold all subject faces\n",
    "images = [] #creating list of images we import\n",
    "#list to hold labels for all subjects\n",
    "classNames = [] #names of image file\n",
    "myList = os.listdir(path)\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ccd7e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aamir Khan', 'Salman Khan', 'Shah Rukh Khan', 'Shreyansh']\n"
     ]
    }
   ],
   "source": [
    "#we use these names to import images one by one\n",
    "for cl in myList: #importing each class names & removing file extension\n",
    "    curImg = cv2.imread(f'{path}/{cl}') \n",
    "    images.append(curImg) #appending images in empty image list\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2617b83",
   "metadata": {},
   "source": [
    "#### Image encoding process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9abc68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Encodings completed\n"
     ]
    }
   ],
   "source": [
    "#defining a function to compute encodings\n",
    "def findEncodings(images):\n",
    "    encodeList = [] #creating empty list that will have all encoded images \n",
    "    for img in images:  #loop through all the images\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)  #convert it into RGB \n",
    "        #encoding face that we've detected\n",
    "        encode = fr.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "\n",
    "    return encodeList\n",
    "\n",
    "encodeListKnown = findEncodings(images) #encoded list for known faces \n",
    "print(len(encodeListKnown))\n",
    "print(\"Encodings completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc63f2",
   "metadata": {},
   "source": [
    "#### Marking attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fafd721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function for marking attendance\n",
    "def markAttendance(name):\n",
    "    with open(r\"C:\\Users\\Dell\\ML projects\\Image processing\\FaceRecognitionProject/Attendance.csv\",'r+') as f:\n",
    "        myDataList = f.readlines() #reading all the lines we've currently in our data\n",
    "        #print(myDataList)# \n",
    "        nameList = []\n",
    "        for line in myDataList: #go through each line one by one\n",
    "            entry = line.split(',') #splitting based on comma\",\" then we've name & time separated\n",
    "            nameList.append(entry[0]) #appending entry of 1st element (i.e \"Name\") in empty list\n",
    "        if name not in nameList: #if name is present then no changes would be made & if not then \n",
    "            now = datetime.now() #creating datetime object #gives date & time\n",
    "            tString = now.strftime('%H:%M') #time format\n",
    "            dString = now.strftime('%d-%m-%Y')\n",
    "            f.writelines(f'\\n{name}, {tString}, {dString}') \n",
    "#markAttendance(\"a\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facf3bd4",
   "metadata": {},
   "source": [
    "#### Image comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f399f694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48983171 0.649358   0.6947672  0.68622694]\n",
      "AAMIR KHAN\n",
      "[0.80100677 0.67016724 0.68146808 0.38096741]\n",
      "SHREYANSH\n",
      "[0.78433278 0.6750338  0.66773161 0.4332694 ]\n",
      "SHREYANSH\n",
      "[0.48977013 0.65440942 0.65598933 0.70223681]\n",
      "AAMIR KHAN\n",
      "[0.41337868 0.6389167  0.69983519 0.7345298 ]\n",
      "AAMIR KHAN\n",
      "[0.45544996 0.68127516 0.68282599 0.72224104]\n",
      "AAMIR KHAN\n",
      "[0.44132153 0.65450241 0.69253137 0.73492072]\n",
      "AAMIR KHAN\n",
      "[0.39923161 0.64490685 0.72266265 0.74125756]\n",
      "AAMIR KHAN\n",
      "[0.38748139 0.6416398  0.71722412 0.74003339]\n",
      "AAMIR KHAN\n",
      "[0.37882093 0.66063381 0.74001731 0.73023272]\n",
      "AAMIR KHAN\n",
      "[0.39901761 0.67410498 0.72841983 0.73889346]\n",
      "AAMIR KHAN\n",
      "[0.40757923 0.66895969 0.7344305  0.76284798]\n",
      "AAMIR KHAN\n",
      "[0.38741681 0.66863987 0.74607359 0.74611296]\n",
      "AAMIR KHAN\n",
      "[0.36145689 0.65946052 0.74931089 0.73434556]\n",
      "AAMIR KHAN\n",
      "[0.38050023 0.67591162 0.7492787  0.74465109]\n",
      "AAMIR KHAN\n",
      "[0.39118758 0.66365508 0.74597271 0.74847767]\n",
      "AAMIR KHAN\n",
      "[0.39011925 0.67463373 0.77508573 0.79234326]\n",
      "AAMIR KHAN\n",
      "[0.39705059 0.65317376 0.72155776 0.71096538]\n",
      "AAMIR KHAN\n",
      "[0.40436072 0.66243055 0.75301507 0.74822138]\n",
      "AAMIR KHAN\n",
      "[0.39301012 0.66962839 0.75490332 0.76503965]\n",
      "AAMIR KHAN\n",
      "[0.41579154 0.67716642 0.73010339 0.75164327]\n",
      "AAMIR KHAN\n",
      "[0.40369393 0.6834188  0.74183665 0.74072824]\n",
      "AAMIR KHAN\n",
      "[0.41449818 0.66931601 0.7372156  0.76087876]\n",
      "AAMIR KHAN\n",
      "[0.40070021 0.64667069 0.73310034 0.73207578]\n",
      "AAMIR KHAN\n",
      "\n",
      " [INFO] Exiting Program \n"
     ]
    }
   ],
   "source": [
    "#find matches bw encodings but here we don't have image to match with.\n",
    "#now that image will be coming from our webcam\n",
    "\n",
    "#initialise the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#loop to get each frame one by one\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "    imgS = cv2.cvtColor(imgS,cv2.COLOR_BGR2RGB) \n",
    "    \n",
    "    facesLocCurframe = fr.face_locations(imgS) \n",
    "    encodeCurFrame = fr.face_encodings(imgS,facesLocCurframe)\n",
    "    \n",
    "    for encodeFace,faceLoc in zip(encodeCurFrame,facesLocCurframe):\n",
    "        matches = fr.compare_faces(encodeListKnown,encodeFace)\n",
    "        faceDist = fr.face_distance(encodeListKnown,encodeFace)\n",
    "        print(faceDist)\n",
    "        \n",
    "        #lowest value in the index will be best match so\n",
    "        matchIndex = np.argmin(faceDist)\n",
    "        \n",
    "        #displaying boundary box & name around face\n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].upper()\n",
    "            print(name)\n",
    "            y1,x2,y2,x1 = faceLoc\n",
    "            y1,x2,y2,x1 = y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,240,0),2)\n",
    "            cv2.rectangle(img,(x1,y2-30),(x2,y2),(0,240,0),-1) #displaying filled box below the rectangle\n",
    "            cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_SIMPLEX,(1/2),(255,255,255),2)\n",
    "            markAttendance(name)\n",
    "            \n",
    "    cv2.imshow(\"Live Face\",img)\n",
    "    k = cv2.waitKey(100) & 0xff \n",
    "    if k == 27: # Press 'ESC' for exiting video\n",
    "        break\n",
    "    elif (k == ord('c')):\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(r\"C:\\Users\\Dell\\ML projects\\Image processing\\FaceRecognitionProject/User_\" + str(name) + \".jpg\",img)\n",
    "        break\n",
    "\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program \")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1fd58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
